# Proyecto de Machine Learning - Modelos Supervisados y No Supervisados

Este proyecto contiene modelos de Machine Learning entrenados para clasificaci√≥n (Regresi√≥n Log√≠stica y KNN) y clustering (K-Means), junto con una aplicaci√≥n web interactiva para realizar predicciones.

##  Descripci√≥n del Proyecto

El proyecto incluye:

1. **Modelos Supervisados (Clasificaci√≥n)** - Dataset: Telco Customer Churn
   - Regresi√≥n Log√≠stica
   - K-Nearest Neighbors (KNN)

2. **Modelo No Supervisado (Clustering)** - Dataset: Credit Card Dataset
   - K-Means Clustering

3. **Aplicaci√≥n Web** - Interfaz interactiva para probar los modelos

##  Instalaci√≥n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Pasos de Instalaci√≥n

1. **Clonar o descargar el repositorio**

2. **Crear un entorno virtual (recomendado)**
   ```bash
   python -m venv venv
   ```

3. **Activar el entorno virtual**
   
   En Windows:
   ```bash
   venv\Scripts\activate
   ```
   
   En Linux/Mac:
   ```bash
   source venv/bin/activate
   ```

4. **Instalar las dependencias**
   ```bash
   pip install -r requirements.txt
   ```

##  Estructura del Proyecto

```
Parcial3/
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                   # Este archivo
‚îú‚îÄ‚îÄ .gitignore                  # Archivos a ignorar en Git
‚îÇ
‚îú‚îÄ‚îÄ backend/                    # L√≥gica del backend
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py         # Funciones para cargar modelos
‚îÇ   ‚îú‚îÄ‚îÄ predictors.py           # Funciones de predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ api.py                  # FastAPI con los endpoints /predict
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # Interfaz de usuario
‚îÇ   ‚îî‚îÄ‚îÄ app.py                  # Aplicaci√≥n web principal (Streamlit)
‚îÇ
‚îú‚îÄ‚îÄ modelos/                    # Carpeta para los modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ logreg_model.pkl        # Modelo de Regresi√≥n Log√≠stica (incluye preprocesador)
‚îÇ   ‚îú‚îÄ‚îÄ knn_model.pkl           # Modelo KNN (incluye preprocesador)
‚îÇ   ‚îú‚îÄ‚îÄ kmeans_model.pkl        # Modelo K-Means
‚îÇ   ‚îú‚îÄ‚îÄ credit_scaler.pkl       # Preprocesador para Credit Card
‚îÇ   ‚îú‚îÄ‚îÄ cluster_profiles.pkl    # (Opcional) Perfiles de clusters
‚îÇ   ‚îî‚îÄ‚îÄ generar_perfiles_clusters.py  # Script de ejemplo
‚îÇ
‚îî‚îÄ‚îÄ notebooks/                  # Notebooks de an√°lisis y entrenamiento
    ‚îú‚îÄ‚îÄ 01_Regresion_Logistica.ipynb
    ‚îú‚îÄ‚îÄ 02_KNN.ipynb
    ‚îî‚îÄ‚îÄ 03_KMeans.ipynb
```

##  Uso de la Aplicaci√≥n Web

### 1. Backend (ejecuci√≥n local opcional)
El frontend consume un backend HTTP desplegado en Render (`https://machinelearning-af44.onrender.com`).  
Si deseas ejecutar el backend localmente:

```bash
uvicorn backend.api:app --reload --host 0.0.0.0 --port 8000
```

Luego, en otra terminal:

```bash
set API_BASE_URL=http://localhost:8000   # Windows PowerShell
export API_BASE_URL=http://localhost:8000  # macOS / Linux
```

Si no defines `API_BASE_URL`, el frontend intentar√° utilizar el backend desplegado en Render.  
En caso de que dicho backend remoto no est√© disponible, la aplicaci√≥n utilizar√° autom√°ticamente
los modelos locales como fallback, siempre que los archivos `.pkl` est√©n en la carpeta `modelos/`.

### 2. Restaurar el backend en Railway

1. **Instala el CLI de Railway** (solo la primera vez)
   ```bash
   npm i -g @railway/cli
   railway login
   ```
2. **Crea o vincula un proyecto**
   ```bash
   railway init                      # crea uno nuevo desde este repo
   # o, si ya tienes un proyecto existente:
   railway link <ID_DEL_PROYECTO>
   ```
3. **Despliega**
   ```bash
   railway up
   ```
   El CLI detectar√° el `Procfile`/`railway.json` a√±adidos y ejecutar√°:
   ```
   uvicorn backend.api:app --host 0.0.0.0 --port $PORT
   ```
   Aseg√∫rate de que la carpeta `modelos/` est√© incluida en el despliegue (contiene los `.pkl`).

4. **Obt√©n la nueva URL** generada por Railway y actualiza el frontend:
   ```bash
   set API_BASE_URL=https://<tu-app>.up.railway.app   # Windows PowerShell
   export API_BASE_URL=https://<tu-app>.up.railway.app # macOS / Linux
   ```
   Tambi√©n puedes definir la variable dentro de los ‚ÄúEnvironment Variables‚Äù del proyecto en la consola de Railway para tenerla siempre disponible.

### 3. Frontend (Streamlit)
### 3. Frontend (Streamlit)

2. **Ejecutar la aplicaci√≥n**
   
   Si `streamlit` est√° en tu PATH:
   ```bash
   streamlit run frontend/app.py
   ```
   
   Si no est√° en tu PATH (m√°s com√∫n):
   ```bash
   python -m streamlit run frontend/app.py
   ```

3. **Abrir en el navegador**
   - La aplicaci√≥n se abrir√° autom√°ticamente en `http://localhost:8501`
   - Si no se abre autom√°ticamente, copia la URL que aparece en la terminal

4. **Usar la aplicaci√≥n**
   - Selecciona el modelo que deseas probar desde el men√∫ lateral
   - Completa el formulario con los datos requeridos
   - Haz clic en el bot√≥n de predicci√≥n
   - Visualiza los resultados

## üìä Modelos Incluidos

### Regresi√≥n Log√≠stica
- **Input**: Variables del dataset Telco Customer Churn
- **Output**: 
  - Probabilidad de abandono (0-100%)
  - Clasificaci√≥n: S√≠/No

### K-Nearest Neighbors (KNN)
- **Input**: Variables del dataset Telco Customer Churn
- **Output**: 
  - Clasificaci√≥n: S√≠/No

### K-Means Clustering
- **Input**: Variables num√©ricas del Credit Card Dataset
- **Output**: 
  - N√∫mero del cluster asignado
  - Descripci√≥n del perfil del cluster

##  Arquitectura y Endpoints

El backend expone los modelos mediante FastAPI en el dominio:

```
https://machinelearning-af44.onrender.com
```

Endpoints disponibles:

- `POST /predict/logistic` ‚Üí Predicci√≥n de Regresi√≥n Log√≠stica (probabilidades y clasificaci√≥n)
- `POST /predict/knn` ‚Üí Predicci√≥n con KNN (clasificaci√≥n)
- `POST /predict/kmeans` ‚Üí Asignaci√≥n de cluster y perfil para K-Means

Cada endpoint recibe un JSON con los campos del formulario y devuelve las m√©tricas que consume el frontend de Streamlit.

## üìì Notebooks de An√°lisis

El proyecto incluye notebooks completos en la carpeta `notebooks/`:

- **01_Regresion_Logistica.ipynb**: An√°lisis completo del modelo de Regresi√≥n Log√≠stica
  - Preprocesamiento de datos
  - Entrenamiento del modelo
  - M√©tricas (Accuracy, Precision, Recall, F1-Score, ROC-AUC)
  - Matriz de confusi√≥n
  - Curva ROC

- **02_KNN.ipynb**: An√°lisis completo del modelo KNN
  - Preprocesamiento de datos
  - Entrenamiento del modelo
  - M√©tricas completas
  - Visualizaciones

- **03_KMeans.ipynb**: An√°lisis completo del modelo K-Means
  - Preprocesamiento de datos
  - M√©todo del codo (Elbow Method)
  - M√©todo de Silhouette
  - Entrenamiento del modelo
  - Interpretaci√≥n de clusters
  - Visualizaciones con PCA
  - Aplicaciones reales

##  Notas Importantes

- Los modelos deben estar entrenados previamente y guardados como archivos `.pkl`
- Los modelos `logreg_model.pkl` y `knn_model.pkl` ya incluyen el preprocesador dentro (son Pipelines)
- Para K-Means, se requiere el archivo `credit_scaler.pkl` para preprocesar los datos
- Se recomienda incluir `cluster_profiles.pkl` con las descripciones de cada cluster para K-Means
- El frontend ya no importa m√≥dulos del backend: todas las predicciones se realizan a trav√©s de peticiones HTTP al API

## üîß Soluci√≥n de Problemas

### Error: "streamlit no se reconoce como comando"
- Usa `python -m streamlit run frontend/app.py` en lugar de solo `streamlit run frontend/app.py`

### Error: "No se pudo conectar con el backend"
- Verifica que `API_BASE_URL` apunte al dominio correcto o que el backend local est√© ejecut√°ndose
- Comprueba tu conexi√≥n a internet si est√°s usando el backend en Render

### Error: "No se encontraron los archivos del modelo"
- Verifica que los archivos `.pkl` est√©n en la carpeta `modelos/`
- Verifica que los nombres de los archivos coincidan:
  - `logreg_model.pkl` (no `logistic_regression_model.pkl`)
  - `knn_model.pkl`
  - `kmeans_model.pkl`
  - `credit_scaler.pkl` (no `credit_card_preprocessor.pkl`)

### Error al realizar predicci√≥n
- Aseg√∫rate de que el preprocesador y el modelo sean compatibles
- Verifica que los datos de entrada tengan el formato correcto
- Aseg√∫rate de usar scikit-learn versi√≥n 1.6.1 (especificada en requirements.txt)

##  Archivos del Repositorio

### Estructura para GitHub:
-  Carpeta `/modelos` con los archivos `.pkl`
-  C√≥digo de la web en `/frontend` y `/backend`
-  README con instrucciones claras
-  `requirements.txt` con todas las dependencias
-  Notebooks limpios en `/notebooks` con:
  - Preprocesamiento
  - Entrenamiento
  - Resultados
  - M√©tricas
  - Gr√°ficas

##  Autores

- Juan Camilo Grajales Lasso
- Isabela Giraldo Vargas
- Maria Camila Espinosa Flores

