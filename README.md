# Proyecto de Machine Learning - Modelos Supervisados y No Supervisados

Este proyecto contiene modelos de Machine Learning entrenados para clasificaciÃ³n (RegresiÃ³n LogÃ­stica y KNN) y clustering (K-Means), junto con una aplicaciÃ³n web interactiva para realizar predicciones.

## ğŸ“‹ DescripciÃ³n del Proyecto

El proyecto incluye:

1. **Modelos Supervisados (ClasificaciÃ³n)** - Dataset: Telco Customer Churn
   - RegresiÃ³n LogÃ­stica
   - K-Nearest Neighbors (KNN)

2. **Modelo No Supervisado (Clustering)** - Dataset: Credit Card Dataset
   - K-Means Clustering

3. **AplicaciÃ³n Web** - Interfaz interactiva para probar los modelos

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Pasos de InstalaciÃ³n

1. **Clonar o descargar el repositorio**

2. **Crear un entorno virtual (recomendado)**
   ```bash
   python -m venv venv
   ```

3. **Activar el entorno virtual**
   
   En Windows:
   ```bash
   venv\Scripts\activate
   ```
   
   En Linux/Mac:
   ```bash
   source venv/bin/activate
   ```

4. **Instalar las dependencias**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“ Estructura del Proyecto

```
Parcial3/
â”‚
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ .gitignore                  # Archivos a ignorar en Git
â”‚
â”œâ”€â”€ backend/                    # LÃ³gica del backend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_loader.py         # Funciones para cargar modelos
â”‚   â”œâ”€â”€ predictors.py           # Funciones de predicciÃ³n
â”‚   â””â”€â”€ api.py                  # FastAPI con los endpoints /predict
â”‚
â”œâ”€â”€ frontend/                   # Interfaz de usuario
â”‚   â””â”€â”€ app.py                  # AplicaciÃ³n web principal (Streamlit)
â”‚
â”œâ”€â”€ modelos/                    # Carpeta para los modelos entrenados
â”‚   â”œâ”€â”€ logreg_model.pkl        # Modelo de RegresiÃ³n LogÃ­stica (incluye preprocesador)
â”‚   â”œâ”€â”€ knn_model.pkl           # Modelo KNN (incluye preprocesador)
â”‚   â”œâ”€â”€ kmeans_model.pkl        # Modelo K-Means
â”‚   â”œâ”€â”€ credit_scaler.pkl       # Preprocesador para Credit Card
â”‚   â”œâ”€â”€ cluster_profiles.pkl    # (Opcional) Perfiles de clusters
â”‚   â””â”€â”€ generar_perfiles_clusters.py  # Script de ejemplo
â”‚
â””â”€â”€ notebooks/                  # Notebooks de anÃ¡lisis y entrenamiento
    â”œâ”€â”€ 01_Regresion_Logistica.ipynb
    â”œâ”€â”€ 02_KNN.ipynb
    â””â”€â”€ 03_KMeans.ipynb
```

## ğŸ¯ Uso de la AplicaciÃ³n Web

### 1. Backend (ejecuciÃ³n local opcional)
El frontend consume un backend HTTP desplegado en Render (`https://machinelearning-af44.onrender.com`).  
Si deseas ejecutar el backend localmente:

```bash
uvicorn backend.api:app --reload --host 0.0.0.0 --port 8000
```

Luego, en otra terminal:

```bash
set API_BASE_URL=http://localhost:8000   # Windows PowerShell
export API_BASE_URL=http://localhost:8000  # macOS / Linux
```

Si no defines `API_BASE_URL`, el frontend intentarÃ¡ utilizar el backend desplegado en Render.  
En caso de que dicho backend remoto no estÃ© disponible, la aplicaciÃ³n utilizarÃ¡ automÃ¡ticamente
los modelos locales como fallback, siempre que los archivos `.pkl` estÃ©n en la carpeta `modelos/`.

### 2. Restaurar el backend en Railway

1. **Instala el CLI de Railway** (solo la primera vez)
   ```bash
   npm i -g @railway/cli
   railway login
   ```
2. **Crea o vincula un proyecto**
   ```bash
   railway init                      # crea uno nuevo desde este repo
   # o, si ya tienes un proyecto existente:
   railway link <ID_DEL_PROYECTO>
   ```
3. **Despliega**
   ```bash
   railway up
   ```
   El CLI detectarÃ¡ el `Procfile`/`railway.json` aÃ±adidos y ejecutarÃ¡:
   ```
   uvicorn backend.api:app --host 0.0.0.0 --port $PORT
   ```
   AsegÃºrate de que la carpeta `modelos/` estÃ© incluida en el despliegue (contiene los `.pkl`).

4. **ObtÃ©n la nueva URL** generada por Railway y actualiza el frontend:
   ```bash
   set API_BASE_URL=https://<tu-app>.up.railway.app   # Windows PowerShell
   export API_BASE_URL=https://<tu-app>.up.railway.app # macOS / Linux
   ```
   TambiÃ©n puedes definir la variable dentro de los â€œEnvironment Variablesâ€ del proyecto en la consola de Railway para tenerla siempre disponible.

### 3. Frontend (Streamlit)
### 3. Frontend (Streamlit)

2. **Ejecutar la aplicaciÃ³n**
   
   Si `streamlit` estÃ¡ en tu PATH:
   ```bash
   streamlit run frontend/app.py
   ```
   
   Si no estÃ¡ en tu PATH (mÃ¡s comÃºn):
   ```bash
   python -m streamlit run frontend/app.py
   ```

3. **Abrir en el navegador**
   - La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en `http://localhost:8501`
   - Si no se abre automÃ¡ticamente, copia la URL que aparece en la terminal

4. **Usar la aplicaciÃ³n**
   - Selecciona el modelo que deseas probar desde el menÃº lateral
   - Completa el formulario con los datos requeridos
   - Haz clic en el botÃ³n de predicciÃ³n
   - Visualiza los resultados

## ğŸ“Š Modelos Incluidos

### RegresiÃ³n LogÃ­stica
- **Input**: Variables del dataset Telco Customer Churn
- **Output**: 
  - Probabilidad de abandono (0-100%)
  - ClasificaciÃ³n: SÃ­/No

### K-Nearest Neighbors (KNN)
- **Input**: Variables del dataset Telco Customer Churn
- **Output**: 
  - ClasificaciÃ³n: SÃ­/No

### K-Means Clustering
- **Input**: Variables numÃ©ricas del Credit Card Dataset
- **Output**: 
  - NÃºmero del cluster asignado
  - DescripciÃ³n del perfil del cluster

## ğŸŒ Arquitectura y Endpoints

El backend expone los modelos mediante FastAPI en el dominio:

```
https://machinelearning-af44.onrender.com
```

Endpoints disponibles:

- `POST /predict/logistic` â†’ PredicciÃ³n de RegresiÃ³n LogÃ­stica (probabilidades y clasificaciÃ³n)
- `POST /predict/knn` â†’ PredicciÃ³n con KNN (clasificaciÃ³n)
- `POST /predict/kmeans` â†’ AsignaciÃ³n de cluster y perfil para K-Means

Cada endpoint recibe un JSON con los campos del formulario y devuelve las mÃ©tricas que consume el frontend de Streamlit.

## ğŸ““ Notebooks de AnÃ¡lisis

El proyecto incluye notebooks completos en la carpeta `notebooks/`:

- **01_Regresion_Logistica.ipynb**: AnÃ¡lisis completo del modelo de RegresiÃ³n LogÃ­stica
  - Preprocesamiento de datos
  - Entrenamiento del modelo
  - MÃ©tricas (Accuracy, Precision, Recall, F1-Score, ROC-AUC)
  - Matriz de confusiÃ³n
  - Curva ROC

- **02_KNN.ipynb**: AnÃ¡lisis completo del modelo KNN
  - Preprocesamiento de datos
  - Entrenamiento del modelo
  - MÃ©tricas completas
  - Visualizaciones

- **03_KMeans.ipynb**: AnÃ¡lisis completo del modelo K-Means
  - Preprocesamiento de datos
  - MÃ©todo del codo (Elbow Method)
  - MÃ©todo de Silhouette
  - Entrenamiento del modelo
  - InterpretaciÃ³n de clusters
  - Visualizaciones con PCA
  - Aplicaciones reales

## ğŸ“ Notas Importantes

- Los modelos deben estar entrenados previamente y guardados como archivos `.pkl`
- Los modelos `logreg_model.pkl` y `knn_model.pkl` ya incluyen el preprocesador dentro (son Pipelines)
- Para K-Means, se requiere el archivo `credit_scaler.pkl` para preprocesar los datos
- Se recomienda incluir `cluster_profiles.pkl` con las descripciones de cada cluster para K-Means
- El frontend ya no importa mÃ³dulos del backend: todas las predicciones se realizan a travÃ©s de peticiones HTTP al API

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "streamlit no se reconoce como comando"
- Usa `python -m streamlit run frontend/app.py` en lugar de solo `streamlit run frontend/app.py`

### Error: "No se pudo conectar con el backend"
- Verifica que `API_BASE_URL` apunte al dominio correcto o que el backend local estÃ© ejecutÃ¡ndose
- Comprueba tu conexiÃ³n a internet si estÃ¡s usando el backend en Render

### Error: "No se encontraron los archivos del modelo"
- Verifica que los archivos `.pkl` estÃ©n en la carpeta `modelos/`
- Verifica que los nombres de los archivos coincidan:
  - `logreg_model.pkl` (no `logistic_regression_model.pkl`)
  - `knn_model.pkl`
  - `kmeans_model.pkl`
  - `credit_scaler.pkl` (no `credit_card_preprocessor.pkl`)

### Error al realizar predicciÃ³n
- AsegÃºrate de que el preprocesador y el modelo sean compatibles
- Verifica que los datos de entrada tengan el formato correcto
- AsegÃºrate de usar scikit-learn versiÃ³n 1.6.1 (especificada en requirements.txt)

## ğŸ—‚ï¸ Archivos del Repositorio

### Estructura para GitHub:
- âœ… Carpeta `/modelos` con los archivos `.pkl`
- âœ… CÃ³digo de la web en `/frontend` y `/backend`
- âœ… README con instrucciones claras
- âœ… `requirements.txt` con todas las dependencias
- âœ… Notebooks limpios en `/notebooks` con:
  - Preprocesamiento
  - Entrenamiento
  - Resultados
  - MÃ©tricas
  - GrÃ¡ficas

## ğŸ‘¥ Autores

[Tu nombre/equipo]

## ğŸ“„ Licencia

[Especificar licencia si aplica]

